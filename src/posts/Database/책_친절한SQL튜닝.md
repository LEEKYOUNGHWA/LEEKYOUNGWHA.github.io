---
title: 친절한 SQL 튜닝
lang: ko-KR
date: 2023/11/18 00:00:00
lastUpdated: 2023/11/18 00:00:0
description: 친절한 SQL 튜닝 요약
meta:
  - name: 친절한 SQL 튜닝
    content: 친절한 SQL 튜닝 요약
tags: ["Book"]
---

# {{ $frontmatter.title }}

[[toc]]

## 1장. SQL 처리 과정과 I/O
### 1.1 SQL 파싱과 최적화
#### 1.1.1 구조적, 집합적, 선언적 질의 언어
#### 1.1.2 SQL 최적화
#### 1.1.3 SQL 옵티마이저
#### 1.1.4 실행계획과 비용
#### 1.1.5 옵티마이저 힌트
### 1.2 SQL 공유 및 재사용
#### 1.2.1 소프트 파싱 vs. 하드 파싱
#### 1.2.2 바인드 변수의 중요성
### 데이터 저장 구조 및 I/O 메커니즘
#### 1.3.1 SQL이 느린 이유
#### 1.3.2 데이터베이스 저장 구조
#### 1.3.3 블록 단위 I/O
#### 1.3.4 시퀀셜 액세스 vs. 랜덤 액세스
#### 1.3.5 논리적 I/O vs. 물리적 I/O
#### 1.3.6 Single Block vs. Multiblock I/O
#### 1.3.7 Table Full Scan vs. Index Range Scan
#### 1.3.8 캐시 탐색 매커니즘

## 2장. 인덱스 기본
### 2.1 인덱스 구조 및 탐색
#### 2.1.1. 미리보는 인덱스 튜닝
#### 2.1.2 인덱스 구조
#### 2.1.3 인덱스 수직적 탐색
#### 2.1.4 인덱스 수평적 탐색
#### 2.1.5 결합 인덱스 구조와 탐색
### 2.2 인덱스 기본 사용법
#### 2.2.1 인덱스를 사용한다는것
#### 2.2.2. 인덱스를 Range Scan 할 수 없는 이유
#### 2.2.3 더 중요한 인덱스 사용 조건
#### 2.2.4 인덱스를 이용한 소트 연산 생략
#### 2.2.5 ORDER BY 절에서 컬럼 가공
#### 2.2.6 SELECT-LIST 에서 컬럼 가공
#### 2.2.7 자동 형변환
### 2.3 인덱스 확장기능 사용법
#### 2.3.1 Index Range Scan
#### 2.3.2 Index Full Scan
#### 2.3.3 Index Unique Scan
#### 2.3.4 Index Skip Scan
#### 2.3.5 Index Fast Full Scan
#### 2.3.6 Index Range Scan Descending
## 3장. 인덱스 튜닝
### 3.1 테이블 액세스 최소화
#### 3.1.1 테이블 랜덤 액세스
#### 3.1.2 인덱스 클러스터링 팩서
#### 3.1.3 인덱스 손익분기점
#### 3.1.4 인덱스 컬럼 추가
#### 3.1.5 인덱스만 읽고 처리
#### 3.1.6 인덱스 구조 테이블
#### 3.1.7 클러스터 테이블
### 3.2 부분범위 처리 활용
#### 3.2.1 부분범위 처리
#### 3.2.2 부분범위 처리 구현
#### OLTP 환경에서 부분범위 처리에 의한 성능개선 원리
### 3.3 인덱스 스캔 효율화
#### 3.3.1 인덱스 탐색
#### 3.3.2 인덱스 스캔 효율성
#### 3.3.3 액세스 조건과 필터 조건
#### 3.3.4 비교 연산자 종류와 컬럼 순서에 다른 군집성
#### 3.3.5 인덱스 선행 컬럼이 등치(=) 조건이 아닐 때 생기는 비효율
#### 3.3.6 BETWEEN 을 IN-List로 전환
#### 3.3.7 Index Skip Scan 활용
#### 3.3.8 IN 조건은 '='인가
#### 3.3.9 BETWEEN과 LIKE 스캔 범위 비교
#### 3.3.10 범위 검색 조건을 남용할 때 생기는 비효율
#### 3.3.11 다양한 옵션 처리 방식의 장단점 비교
#### 3.3.12 함수호출부하 해소를 위한 인덱스 구성
### 3.4 인덱스 설계
#### 3.4.1 인덱스 설계가 어려운 이유
#### 3.4.2 가장 중요한 두가지 선택 기준
#### 3.4.3 스캔 효율성 이외의 판단 기준
#### 3.4.4 공식을 초월한 전략적 설계
#### 3.4.5 소트 연산을 생략하기 위한 컬럼 추가
#### 3.4.6 결합 인덱스 선택도
#### 3.4.7 중복 인덱스 제거
#### 3.4.8 인덱스 설계도 작성
## 4장. 조인 튜닝
### 4.1 NL튜닝
#### 4.1.1 기본 매커니즘
#### 4.1.2 NL 조인 실행계획 제어
#### 4.1.3 NL 조인 수행 과정 분석
#### 4.1.4 NL 조인 튜닝 포인트
#### 4.1.5 NL 조인 특징 요약
#### 4.1.6 NL 조인 튜닝 실습
#### 4.1.7 NL 조인 확장 매커니즘
### 4.2 소트 머지 조인
#### 4.2.1 SGA vs. PGA
#### 4.2.2 기본 매커니즘
#### 4.2.3 소트머지 조인이 빠른 이유
#### 4.2.4 소트머지 조인의 주용도
#### 4.2.5 소트머지 조인 제어하기
#### 4.2.6 소트머지 조인 특징 요약
### 4.3 해시 조인
#### 4.3.1 기본 매커니즘
#### 4.3.2 해시조인이 빠른 이유
#### 4.3.3 대용량 Build Input 처리
#### 4.3.4 해시 조인 실행계획 제어
#### 4.3.5 조인 메소드 선택 기준
### 4.4 서브쿼리 조인
#### 4.4.1 서브쿼리 변환이 필요한 이유
#### 4.4.2 서브쿼리와 조인
#### 4.4.3 뷰(View) 와 조인
#### 4.4.4 스칼라 서브쿼리 조인
## 5장. 소트 튜닝
### 5.1 소트 연산에 대한 이해
#### 5.1.1 소트 수행 과정
#### 5.1.2 소트 오퍼레이션
### 5.2 소트가 발생하지 않도록 SQL 작성
#### 5.2.1 Union vs. Union All
#### 5.2.2 Exists 활용
### 5.3 인덱스를 이용한 소트 연산 생략
#### 5.3.1 Sort Order By 생략
#### 5.3.2 Top N 쿼리
#### 5.3.3 최소값/최대값 구하기
#### 5.3.4 이력 조회
#### 5.3.5 Sort Group By 생략
### 5.4 Sort Area를 적게 사용하도록 SQL 작성
#### 5.4.1 소트 데이터 줄이기
#### 5.4.2 Top N 쿼리의 소트 부하 경감 원리
#### 5.4.3 Top N 쿼리가 아닐 때 발생하는 소트 부하
#### 5.4.4 분석함수에서의 Top N 소트
## 6장. DML 튜닝
### 6.1 기본 DML 튜닝
#### 6.1.1 DML 성능에 영향을 미치는 요서
#### 6.1.2 데이터베이스 Call 과 성능
#### 6.1.3 Array Processing 활용
#### 6.1.4 인덱스 및 제약 해제를 통한 대량 DML 튜닝
#### 6.1.5 수정가능 조인 뷰
#### 6.1.6 MERGE문 활용
### 6.2 Direct Path I/O 활용
#### 6.2.1 Direct Path I/O
#### 6.2.2 Direct Path Insert
#### 6.2.3 병렬 DML
### 6.3 파티션을 이용한 DML 튜닝
#### 6.3.1 테이블 파티션
#### 6.3.2 인덱스 파티현
#### 6.3.3 파티션을 활용한 대량 UPDATE 튜닝
#### 6.3.4 파티션을 활용한 대량 DELETE 튜닝
#### 6.4.5 파티션을 활용한 대량 INSERT 튜닝
### 6.4 Lock 과 트랜잭션 동시성 제어
#### 6.4.1 오라클 Lock
#### 6.4.2 트랜잭션 동시성 제어
#### 6.4.3 채번 방식에 따른 INSERT 성능 비교

## 7장. 옵티마이저
### 7.1 통계정보와 비용 계산 원리
#### 7.1.1 선택도와 카디널리티
- 선택도(Selectivity) : 전체 레코드 중에서 조건절에 의해 선택되는 레코드 비율
- 선택도 = 1/NDV(컬럼 값 종류 개수 'Number of Distinct Values')
- 카디널리티(Cardinality) : 전체 레코드 중에서 조건절에 의해 선택되는 레코드 개수
- 카디널리티 = 총 로우 수 X 선택도 = 총 로우수 / NDV
- ex : 상품분류컬럼에 '가전', '의류', '식음료', '생활용품' 네개의 값이 있을때, 선택도는 25%(1/4). 전체 레코드가 10만건이면 카디널리티는 2만5천이다.
- 옵티마이저는 이렇게 카디널리티를 구하고, 그만큼의 데이터를 액세스 하는 데 드는 비용을 계산해서 테이블 액세스 방식, 조인 순서, 조인 방식 등을 결정. 비용을 계산하는 출발점은 선택도다. 선택도를 잘못 계산하면 카티널리티와 비용도 잘못 계산하고 결과적으로 비효율 적인 액세스 방식과 조인 방식 선택
- 선택도를 계산할때 NDV를 사용하므로 통계정보 수집 과정에서 이 값을 정확히 구하는 것이 매우 중요하다. 통계정보 수집주기, 샘플링 비율 등을 잘 결정해야 하는 이유다.
#### 7.1.2 통계정보
```mermaid
flowchart LR
    a[통계정보] --- b[오브젝트통계]
    a --- 시스템통계
    b --- 테이블통계
    b --- 인덱스통계
    b --- c["컬럼통계(히스토그램포함)"]
```
##### (1) 테이블 통계
```sql
-- 테이블 통계를 수집하는 명령어
begin
	dbms_stats.gather_table_stats('scott','emp');
end;
/
```
``` sql
-- 수집된 테이블 통계정보는 아래와 같이 조회할 수 있고, all_tab_statistics 뷰 에서도 같은 정보를 확인할 수 있다
select num_rows, block, avg_row_len, sample_size, last_analyzed
from all_tables
where owner = 'SCOTT'
and table_name = 'EMP'
```
|통계항목| 설명 |
|--|--|
| NUM_ROWS | 테이블에 저장된 총 레코드 개수 |
| BLOCKS | 테이블 블록 수 = '사용된' 익스텐트(데이터가 한건이라도 입력된 적이 잇는 모든 익스텐트) 에 속한 총 블록 수
| AVG_ROW_LEN | 레코드당 평균 길이|
| SAMPLE_SIZE | 샘플링한 레코드 수|
| LAST_ANALYZED| 통계정보 수집 일시|
##### (2)인덱스 통계
```sql
-- 인덱스 통계만 수집
begin
	dbms_stats.gather_index_stats (ownname => 'scott', indname => 'emp_x01');
end;
\
-- 테이블 통계를 수집하면서 인덱스 통계도 수집
begin
	dbms_stats.gather_table_stats ('scott','emp', cascade=> true);
end;
\
```
```sql
-- 수집된 인덱스 통계정보 조회, all_ind_statistics 뷰에서도 같은 정보 확인 가능
select blevel, leaf_blocks, num_rows, distinct_keys
	 , avg_leaf_blocks_per_key, avg_data_blocks_per_key, clustering_factor
	 , sample_size, last_analyzed
  from all_indexes
 where owner = 'SCOTT'
   and table_name = 'EMP'
   and index_name = 'EMP_X01'
```
|통계항목|설명|용도
|--|--|--|
| BLEVEL | 브랜치 레벨의 약자. 인덱스 루트에서 리프 블록에 도달하기 직전까지 읽게 되는 블록의 수| 인덱스 수직적 탐색 비용 계산(2장 1절(2.1) 과 3장3절(3.3) 참조)|
|LEAF_BLOCK|인덱스 리프 블록 총 개수| 인덱스 수평적 탐색 비용 계산(2.1)(3.3)참조|
|NUM_ROWS|인덱스에 저장된 레코드 개수| 인덱스 수평적 탐색 비용 계산(2.1)(3.3)참조|
|DISTINCT_KEYS|인덱스 키값의 조합으로 만들어지는 값의 종류 개수. 예를 들어 C1+C2로 구성한 인덱스에서 C1컬럼에 3개, C2컬럼에 4개 값이 있으면 최대 12개의 값의 종류가 만들어 지는데, 인덱스에 저장된 데이터 기준으로 실제 입력된 값의 종류 개수를 구해놓은 수치. 인덱스 키값을 모두 '=' 조건으로 조회할 때의 선택도(Selectivity)를 계산하는데 사용| 인덱스 수평적 탐색 비용 계산(2.1)(3.3)참조|
|AVG_LEAF_BLOCKS_PER_KEY|인덱스 키값을 모두 '=' 조건으로 조회할 때 읽게 될 리프 블록 개수| 인덱스 수평적 탐색 비용 계산(2.1)(3.3)참조|
|AVG_DATA_BLOCKS_PER_KEY|인덱스 키값을 모두 '=' 조건으로 조회할 때 읽게 될 테이블블록 개수|테이블 액세스 비용 계산(3.1)참조|
|CLUSTERING_FACTOR| 인덱스 키값 기준으로 테이블 데이터가 모여 있는 정도. 인덱스 전체 레코드를 스캔하면서 테이블 레코드를 찾아 갈 때 읽게 될 테이블 블록 개수를 미리 계싼해 놓은 수치(3.1.2)참조|테이블 액세스 비용 계산(3.1)참조|
##### (3) 컬럼 통계
```sql
select num_distinct, density, avg_col_len, low_value, high_value, num_nulls
     , last_analyzed, sample_size
  from all_tab_columns
 where owner = 'SCOTT'
   and table_name = 'EMP'
   and column_name = 'DEPTNO';
```
| 통계항목 | 설명 |
| -- | -- |
| NUM_DISTINCT | 컬럼 값의 종류 개수(NVD,Number of Distinct Values) 예를 들어 성별 컬럼이면 2 |
| DEINSITY | '=' 조건으로 검색할때의 선택도를 미리 구해놓은 값 |
| AVG_COL_LEN | 컬럼 평균 길이(Bytes) |
| LOW_VALUE | 최소값 |
| HIGH_VALUE | 최대값 |
| NUM_NULLS | 값이 NULL 인 레코드 수 |
##### 컬럼 히스토그램
- '=' 조건에 대한 선택도 =  `1/NUM_DISTINCT` 또는 미리 구해놓은 DENSITY 값을 이용하면 된다.
- 데이터 분포가 균일하지 못한 경우 공식이 잘 들어맞지 않음. -> 비용 잘못 산정하여 최적이 아닌 실행계획으로 이어진다.
- 따라서 옵티마이저는 일반적인 컬럼 통계 외에 히스토그램을 추가로 활용한다.
```mermaid
pie title 아파트 매물 테이블에서 '시도구분' 컬럼에 대한 히스토그램을 원형 그래프로 표현
         "서울시" : 8
         "경기도" : 5
         "충청도" : 1
         "전라도" : 1
         "경상도 " : 1
         "제주도" : 0.8
         "강원도" : 0.6
```
|히스토그램 유형|설명|
|--|--|
|도수분포(FREQUENCY)|값별로 빈도수 저장|
|높이균형(HEIGHT_BALANCED)|각 버킷의 높이가 동일하도록 데이터 분포 관리|
|상위도수분포(TOP-FREQUENCY)|많은 레코드를 가진 상위 n개 값에 대한 빈도수 저장(12c이상)|
|하이브리드(HYBRID)|도수분포와 높이균형 히스토그램의 특성 결합|
```sql
-- 히스토그램 수집. 테이블 통계 수집할때 method_opt 파라미터를 지정하면 된다
begin
	dbms_stats.gather_table_stats('scott','emp'
	, cascade=>false, method_opt=>'for columns ename size 10, deptno size 4');
end;
\
```
```sql
begin
	dbms_stats.gather_table_stats('scott','emp'
	, cascade=>false, method_opt=>'for all columns size 75');
end;
\
begin
	dbms_stats.gather_table_stats('scott','emp'
	, cascade=>false, method_opt=>'for all columns size auto');
end;
\
```
```sql
-- 수집된 컬럼 히스토그램 조회, all_tab_histograms 뷰에서도 같은 정보를 확인할 수 있다
select endpoint_value, endpoint_number
  from all_histograms
 where owner ='SCOTT'
   and table_name = 'EMP'
   and column_name = 'DEPTNO'
 order by endpoint_value;
 ```
 ##### (4) 시스템 통계
 - 시스템통계 : 어플리케이션 및 하드웨어 성능 특성을 측정한 것. CPU 속도, 평균적인 Single Block I/O 속도, 평균적인 Multiblock I/O 속도, 평균적인 Multiblock I/O 개수, I/O 서브시스템의 최대 처리량(Throughput), 병렬 Slave의 평균적인 처리량(Throuthput)
 - 시스템 사양, 애플리케이션 특성(OLAP, DW) 및 동시 트랜잭션 발생량에 따라서도 성능 특성이 달라진다. 이에 오라클에서 특성 반영을 위해 9i부터 시스템 통계 수집 기능 도입
 ```sql
 -- 시스템 통계 조회
 select sname, pname, pval1, pval2 from sys.aux_stats$;
 ``` 

#### 7.1.3 비용 계산 원리
### 7.2 옵티마이저에 대한 이해
#### 7.2.1 옵티마이저 종류
#### 7.2.2 옵티마이저 모드
#### 7.2.3 옵티마이저에 영향을 미치는 요소
#### 7.2.4 옵티마이저의 한계
#### 7.2.5 개발자의 역할
#### 7.2.6 튜닝 전문가 되는 공부방법

## 부록. SQL 분석 도구
### 1. 실행계획 확인
### 2. AutoTrace
### 3. SQL 트레이스
### 4. DBMS_XPLAN 패키지
### 5. 실시간 SQL 모니터링
### 6. V$SQL


